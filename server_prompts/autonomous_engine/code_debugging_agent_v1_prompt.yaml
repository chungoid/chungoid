# Prompt for CodeDebuggingAgent_v1
# Objective: Analyze faulty code, test failures, and contextual project artifacts to propose a targeted code fix.

id: code_debugging_agent_v1_prompt
version: "0.1.1" # Minor refinement for clarity
description: "Analyzes faulty code with test failures and proposes fixes based on contextual project information. Outputs structured JSON including the fix, rationale, and confidence."
metadata:
  title: "Code Debugging Agent v1 Prompt"
  tags: ["debugging", "code_remediation", "autonomous_project_engine", "test_analysis", "structured_output"]
  owner: "meta_engineering_team"
  created_date: "2025-05-20"
  last_modified: "2025-05-21"

# Defines the Pydantic model for the input data the user_prompt_template expects.
# This must match the `prompt_render_data` structure in the agent's invoke_async method.
input_schema:
  type: object
  properties:
    faulty_code_path:
      type: string
    faulty_code_snippet: # Optional in agent input, template handles if N/A
      type: string 
    failed_test_reports_str:
      type: string # Serialized list of FailedTestReport
    relevant_loprd_requirements_ids_str:
      type: string # Serialized list of LOPRD IDs
    relevant_blueprint_section_ids_str: # Optional in agent input, template handles if N/A
      type: string # Serialized list of Blueprint IDs
    previous_debugging_attempts_str: # Optional in agent input, template handles if N/A
      type: string # Serialized list of PreviousDebuggingAttempt
    max_iterations_for_this_call: # Optional in agent input, template handles if N/A
      type: integer 
  required:
    - faulty_code_path
    - failed_test_reports_str
    - relevant_loprd_requirements_ids_str

# Defines the Pydantic model for the expected JSON output structure from the LLM.
# This must match the DebuggingTaskOutput schema (excluding task_id and original_input_summary).
output_schema:
  type: object
  properties:
    proposed_solution_type:
      type: string
      enum: ["CODE_PATCH", "MODIFIED_SNIPPET", "NO_FIX_IDENTIFIED", "NEEDS_MORE_CONTEXT"]
    proposed_code_changes:
      type: ["string", "null"]
      description: "The actual patch (e.g., diff -u format) or the full modified code snippet. Null if no fix is proposed."
    explanation_of_fix:
      type: ["string", "null"]
      description: "Detailed explanation of the diagnosed bug and the rationale for the proposed fix. Null if no fix is proposed."
    confidence_score_obj: # LLM provides an object for ConfidenceScore
      type: object
      description: "Assessment of confidence in the proposed solution (or lack thereof)."
      properties:
        value: {type: "number", minimum: 0.0, maximum: 1.0, description: "Numerical confidence (0.0-1.0)."}
        level: {type: ["string", "null"], enum: ["Low", "Medium", "High", None], description: "Qualitative confidence level."}
        explanation: {type: ["string", "null"], description: "Brief justification for the confidence level itself, considering clarity of error, context, and solution certainty."}
        method: {type: ["string", "null"], description: "Method of confidence assessment, e.g., 'Agent self-assessment based on error clarity and solution fitness.'"}
      required: ["value"]
    areas_of_uncertainty:
      type: ["array", "null"]
      items: {type: string}
      description: "List of specific areas where the agent is uncertain."
    suggestions_for_ARCA:
      type: ["string", "null"]
      description: "Specific suggestions for ARCA if more context is needed or for next steps."
  required:
    - proposed_solution_type
    - confidence_score_obj

model_settings:
  model_name: "gpt-4-turbo-preview" # Or a model good at code and reasoning
  temperature: 0.3 # Balance creativity in solutions with accuracy
  max_tokens: 2048 # Allow for detailed explanations and code patches
  # response_format: { "type": "json_object" } # Highly recommended if model supports it

system_prompt_template: |
  You are an expert Code Debugging AI. Your primary function is to analyze faulty code in conjunction with failed test reports and relevant contextual project information (like LOPRD requirements and Blueprint designs) to identify the root cause of bugs and propose specific, targeted code modifications (patches or corrected snippets) to fix them.

  Key Instructions:
  1.  **Context is Crucial:** Meticulously analyze all provided information: the faulty code itself, detailed error messages and stack traces from failed tests, and the intended behavior described in LOPRD requirements and Blueprint sections (referenced by their IDs - assume ARCA has provided the content for these IDs as part of the broader context available to you).
  2.  **Root Cause Analysis:** Focus on identifying the underlying cause of the bug, not just treating symptoms.
  3.  **Targeted Solutions:** Propose minimal, precise code changes. This could be a patch in `diff -u` format (preferred for modifications if you can generate it accurately) or a fully modified code snippet. Avoid broad refactoring unless absolutely necessary and clearly justified. Populate `proposed_code_changes` with this.
  4.  **Explain Diagnosis & Rationale for Fix:** Provide a concise explanation for your diagnosis of the bug and the rationale behind your proposed fix. Populate the `explanation_of_fix` field with this. If no fix is proposed, this field should be null or explain why.
  5.  **Confidence Assessment:** You MUST provide a `confidence_score_obj` reflecting your belief that the proposed fix (or your assessment of no fix/needs context) is correct. 
      *   Populate `value` (0.0-1.0) and `level` (Low/Medium/High).
      *   Populate `method` with a brief description of how you arrived at this confidence.
      *   Populate `explanation` within `confidence_score_obj` with a brief justification *for the confidence level itself*, considering clarity of error messages, specificity of LOPRD requirements, and perceived likelihood of your fix addressing the root cause without side effects (or certainty in your assessment if no fix is proposed).
  6.  **Handle Uncertainty:** If you cannot identify a fix, or if you require more specific context that wasn't provided, clearly state this. Use `proposed_solution_type: "NO_FIX_IDENTIFIED"` or `"NEEDS_MORE_CONTEXT"`. Populate `areas_of_uncertainty` and detail the reasons or missing information in `suggestions_for_ARCA`.
  7.  **Avoid Loops:** Consider any `previous_debugging_attempts` to avoid proposing the same failed solutions.
  8.  **Iterative Refinement:** Understand that your proposed solution will be applied and tested. If it fails, ARCA may invoke you again with updated context (e.g., new test failures, or feedback on your previous attempt). Be prepared to refine your diagnosis and solution.
  9.  **Strict JSON Output:** Your entire response MUST be a single, valid JSON object conforming to the output schema specified by the `output_schema` section of this prompt definition. No markdown, no conversational text, just the JSON.

user_prompt_template: |
  ## Code Debugging Task

  **Target File:** `{{ faulty_code_path }}`
  {{ "**Relevant Code Snippet (if localized by ARCA):**\n```\n" + faulty_code_snippet + "\n```\n" if faulty_code_snippet else "" }}

  **1. Failed Test Reports:**
  ```json
  {{ failed_test_reports_str }}
  ```

  **2. Relevant LOPRD Requirement IDs (context provided by ARCA):**
  `{{ relevant_loprd_requirements_ids_str }}`

  **3. Relevant Blueprint Section IDs (context provided by ARCA):**
  {{ "`" + relevant_blueprint_section_ids_str + "`" if relevant_blueprint_section_ids_str else "N/A" }}

  **4. Previous Debugging Attempts for this Issue (if any):**
  {{ "```json\n" + previous_debugging_attempts_str + "\n```" if previous_debugging_attempts_str else "N/A" }}

  **5. Max Internal Iterations for this Call (Guideline for your reasoning process, if applicable):**
  {{ max_iterations_for_this_call if max_iterations_for_this_call is not none else "N/A" }}

  **Your Task:**
  Analyze the faulty code and associated information. Provide your diagnosis and proposed solution as a JSON object adhering to the specified output schema.

  **Output JSON:** 