# Prompt for CodeDebuggingAgent_v1 - REPURPOSED as Debug/Test/Refactor Agent
# Objective: Debug faulty code, generate tests, and refactor when necessary to ensure robust, working solutions

id: code_debugging_agent_v1_prompt
version: "2.0.0" # Major version bump - completely repurposed from analysis-only to action-oriented
description: "Debug/Test/Refactor Agent: Analyzes faulty code, generates comprehensive tests, applies fixes, and refactors for robustness. Outputs structured JSON with actual code changes, test code, and validation results."
metadata:
  title: "Code Debug/Test/Refactor Agent v1 Prompt"
  tags: ["debugging", "testing", "refactoring", "code_generation", "quality_assurance", "autonomous_project_engine"]
  owner: "meta_engineering_team"
  created_date: "2025-01-27"
  last_modified: "2025-01-27"

# Updated to match existing DebuggingTaskInput schema
input_schema:
  type: object
  properties:
    task_id:
      type: string
      description: "Unique identifier for this debugging task"
    project_id:
      type: string
      description: "Identifier for the current project"
    faulty_code_path:
      type: string
      description: "Path to the code file needing debugging"
    faulty_code_snippet:
      type: string
      description: "Optional specific code snippet if already localized"
    failed_test_reports:
      type: array
      items:
        type: object
        properties:
          test_name: {type: string}
          error_message: {type: string}
          stack_trace: {type: string}
          expected_behavior_summary: {type: string}
      description: "List of structured test failure objects"
    relevant_loprd_requirements_ids:
      type: array
      items: {type: string}
      description: "List of LOPRD requirement IDs relevant to the faulty code"
    relevant_blueprint_section_ids:
      type: array
      items: {type: string}
      description: "List of Blueprint section IDs relevant to the code's design"
    previous_debugging_attempts:
      type: array
      items:
        type: object
        properties:
          attempted_fix_summary: {type: string}
          outcome: {type: string}
      description: "List of previous fixes attempted for this issue"
    max_iterations_for_this_call:
      type: integer
      description: "Limit for this specific debugging invocation's internal reasoning"
    project_specifications:
      type: object
      description: "Intelligent project specifications from orchestrator analysis"
    intelligent_context:
      type: boolean
      description: "Whether intelligent project specifications are provided"
    user_goal:
      type: string
      description: "Original user goal for context"
    project_path:
      type: string
      description: "Project path for context"
  required:
    - faulty_code_path
    - failed_test_reports
    - relevant_loprd_requirements_ids

# Updated to match existing DebuggingTaskOutput schema but enhanced with new capabilities
output_schema:
  type: object
  properties:
    proposed_solution_type:
      type: string
      enum: ["CODE_PATCH", "MODIFIED_SNIPPET", "NO_FIX_IDENTIFIED", "NEEDS_MORE_CONTEXT"]
      description: "Type of solution being proposed"
    proposed_code_changes:
      type: ["string", "null"]
      description: "The actual patch (diff format) or full modified code snippet. Can include both fixes AND test code."
    explanation_of_fix:
      type: ["string", "null"]
      description: "Detailed explanation of diagnosed issues, proposed fixes, generated tests, and refactoring decisions"
    confidence_score_obj:
      type: object
      properties:
        value: {type: number, minimum: 0.0, maximum: 1.0}
        level: {type: string, enum: ["Low", "Medium", "High"]}
        explanation: {type: string}
        method: {type: string}
      required: ["value"]
      description: "Assessment of confidence in the proposed solution"
    areas_of_uncertainty:
      type: array
      items: {type: string}
      description: "List of specific areas where the agent is uncertain"
    suggestions_for_ARCA:
      type: string
      description: "Specific suggestions for ARCA regarding next steps, additional testing, or deployment considerations"
  required:
    - proposed_solution_type
    - confidence_score_obj

system_prompt: |
  You're a debugging agent in my autonomous development system. I need you to be self-sufficient and effective.

  **What I need:** Fix broken code and give me working tests. Don't just analyze - actually solve the problem.

  **How to be effective:**
  - Use your tools: Read files, search the codebase, look up documentation, research solutions
  - Understand context: This isn't isolated code - it's part of a larger project
  - Be thorough: Fix root causes, not symptoms
  - Deliver complete solutions: Working code + tests that prove it works
  - Be practical: Focus on solutions that actually work, not theoretical perfection

  **Your workflow:**
  1. **Gather context** - Use file tools to understand the codebase structure, dependencies, related code
  2. **Diagnose properly** - Don't just look at the error, understand why it's happening  
  3. **Research solutions** - Use web search for best practices, common fixes, framework docs
  4. **Fix comprehensively** - Address the root issue and any related problems you find
  5. **Test thoroughly** - Generate tests that validate your fix and prevent regressions
  6. **Validate everything** - Make sure your code actually runs and integrates properly

  **Output format:** JSON with `proposed_code_changes` containing both fixed code and tests, plus clear explanation of what was broken and how you fixed it.

  **Quality bar:** I should be able to take your output, apply it, and have working code with good test coverage. If you're unsure about something, research it or say so in your uncertainty areas.

  Work autonomously. Use your tools. Deliver complete solutions.

user_prompt: |
  ## Debug/Test/Refactor Task

  **Target File:** `{{ faulty_code_path }}`
  {{ "**Code Snippet (if localized):**\n```\n" + faulty_code_snippet + "\n```\n" if faulty_code_snippet else "" }}

  **1. Failed Test Reports:**
  ```json
  {{ failed_test_reports | tojson(indent=2) if failed_test_reports else "[]" }}
  ```

  **2. Relevant LOPRD Requirement IDs:**
  `{{ relevant_loprd_requirements_ids | join(", ") if relevant_loprd_requirements_ids else "No specific requirements" }}`

  **3. Relevant Blueprint Section IDs:**
  {{ "`" + (relevant_blueprint_section_ids | join(", ")) + "`" if relevant_blueprint_section_ids else "N/A" }}

  **4. Previous Debugging Attempts:**
  {{ "```json\n" + (previous_debugging_attempts | tojson(indent=2)) + "\n```" if previous_debugging_attempts else "N/A" }}

  **5. User Goal:**
  {{ user_goal if user_goal else "General code improvement and testing" }}

  **6. Project Context:**
  {{ "Project ID: " + project_id if project_id else "No project ID provided" }}
  {{ "Project Path: " + project_path if project_path else "" }}

  {% if intelligent_context and project_specifications %}
  **7. Intelligent Project Context:**
  ```json
  {{ project_specifications | tojson(indent=2) }}
  ```
  {% endif %}

  ## YOUR COMPREHENSIVE MISSION
  
  Perform complete Debug/Test/Refactor workflow:
  
  1. **ANALYZE**: Review the code, errors, and requirements thoroughly
  2. **DEBUG**: Identify and fix all issues in the code
  3. **TEST**: Generate comprehensive test suite to validate functionality
  4. **REFACTOR**: Improve code structure and maintainability where beneficial
  5. **VALIDATE**: Ensure all changes work correctly and meet requirements

  **IMPORTANT**: In your `proposed_code_changes`, provide BOTH the fixed code AND the test code, clearly separated with comments indicating file paths and purposes.

  **Output your complete JSON response with all required fields populated.**

model_settings:
  temperature: 0.3
  max_tokens: 4000